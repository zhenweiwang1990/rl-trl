# è¯¦ç»†æ—¶é—´ç»Ÿè®¡å’Œ Thinking åˆ†æ

## æ¦‚è¿°

ç°åœ¨ç³»ç»Ÿä¼šè®°å½•æ¯ä¸ª rollout çš„è¯¦ç»†æ—¶é—´ç»Ÿè®¡ï¼ŒåŒ…æ‹¬ï¼š

1. **æ¯ä¸ª turn çš„æ—¶é—´ç»Ÿè®¡**ï¼š
   - LLM ç”Ÿæˆæ—¶é—´ï¼ˆç²¾ç¡®åˆ°æ¯«ç§’ï¼‰
   - LLM token æ•°é‡ï¼ˆè¾“å…¥/è¾“å‡ºï¼‰
   - å·¥å…·æ‰§è¡Œæ—¶é—´
   - Turn æ€»æ—¶é—´

2. **Query çº§åˆ«çš„æ—¶é—´ç»Ÿè®¡**ï¼š
   - Query æ€»å¤„ç†æ—¶é—´
   
3. **Group çº§åˆ«çš„æ—¶é—´ç»Ÿè®¡**ï¼š
   - Group æ€»æ—¶é—´
   - å¹³å‡ query æ—¶é—´
   
4. **Step çº§åˆ«çš„æ—¶é—´ç»Ÿè®¡**ï¼š
   - Rollout æ”¶é›†æ—¶é—´
   - Advantage è®¡ç®—æ—¶é—´
   - Training æ—¶é—´
   - Step æ€»æ—¶é—´

5. **Eval çº§åˆ«çš„æ—¶é—´ç»Ÿè®¡**ï¼š
   - Eval æ€»æ—¶é—´
   - å¹³å‡ query æ—¶é—´

## ä½¿ç”¨æ–¹æ³•

### 1. å¯ç”¨è¯¦ç»†æ—¥å¿—è®°å½•

è®­ç»ƒæ—¶æ·»åŠ  `--enable-detailed-logging` å‚æ•°ï¼š

```bash
# æœ¬åœ°è®­ç»ƒ
python train_grpo_linksearch.py --mode masked --enable-detailed-logging

# Docker è®­ç»ƒ
./scripts/docker_train_linksearch.sh --enable-detailed-logging
```

è¿™ä¼šå°†è¯¦ç»†çš„ rollout æ—¥å¿—ä¿å­˜åˆ° `outputs/rollout_logs/` ç›®å½•ã€‚

### 2. æŸ¥çœ‹å®æ—¶æ—¥å¿—ä¸­çš„ thinking

å¦‚æœä½ æƒ³åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å®æ—¶æŸ¥çœ‹æ¨¡å‹çš„åŸå§‹è¾“å‡ºï¼ˆåŒ…æ‹¬å¯èƒ½çš„ thinkingï¼‰ï¼Œè®¾ç½®ç¯å¢ƒå˜é‡ï¼š

```bash
# åœ¨ .env æ–‡ä»¶ä¸­æ·»åŠ 
SHOW_RAW_OUTPUT="true"
```

æˆ–è€…åœ¨ä»£ç ä¸­è®¾ç½®ï¼š

```python
policy_config = PolicyConfig(
    show_raw_output=True,  # æ˜¾ç¤ºæ¨¡å‹åŸå§‹è¾“å‡º
    verbose=True,
)
```

### 3. åˆ†æå·²ä¿å­˜çš„æ—¥å¿—

ä½¿ç”¨åˆ†æè„šæœ¬æ¥æŸ¥çœ‹å“ªäº› turn æœ‰å¼‚å¸¸é•¿çš„è¾“å‡ºï¼š

```bash
# åŸºæœ¬åˆ†æ
python scripts/analyze_rollout_timing.py

# æ˜¾ç¤º >= 500 token çš„ turn çš„åŸå§‹è¾“å‡ºé¢„è§ˆ
python scripts/analyze_rollout_timing.py --min-output-tokens 500 --show-raw-output

# æŒ‡å®šæ—¥å¿—ç›®å½•
python scripts/analyze_rollout_timing.py --logs-dir outputs/rollout_logs
```

### 4. ä¼˜åŒ–æ€§èƒ½ï¼šå‡å°‘ MAX_TOKENS

å¦‚æœå‘ç°æ¨¡å‹è¾“å‡ºäº†å¤§é‡ thinking å†…å®¹æˆ–è€… token æ•°è¿‡å¤šï¼Œå¯ä»¥é™ä½ `MAX_TOKENS`ï¼š

```bash
# åœ¨ .env æ–‡ä»¶ä¸­
MAX_TOKENS="512"  # ä» 4096 é™ä½åˆ° 512
```

å¯¹äºå·¥å…·è°ƒç”¨ä»»åŠ¡ï¼Œ512 æˆ– 1024 é€šå¸¸å°±è¶³å¤Ÿäº†ã€‚

## æ€§èƒ½è¯Šæ–­

### å¸¸è§é—®é¢˜

#### 1. è¾“å‡º token æ•°å¼‚å¸¸é«˜ï¼ˆ> 500ï¼‰

**ç—‡çŠ¶**ï¼šä¸€ä¸ªç®€å•çš„å·¥å…·è°ƒç”¨å´è¾“å‡ºäº† 700+ tokens

**å¯èƒ½åŸå› **ï¼š
- æ¨¡å‹åœ¨è¾“å‡ºå·¥å…·è°ƒç”¨å‰è¿›è¡Œäº† "thinking"
- System prompt å¯èƒ½éšå¼é¼“åŠ±äº†æ¨ç†
- æ¨¡å‹æœ¬èº«æœ‰æ€è€ƒå€¾å‘ï¼ˆå¦‚ Qwen3ï¼‰

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. ä½¿ç”¨åˆ†æè„šæœ¬æŸ¥çœ‹åŸå§‹è¾“å‡ºï¼š
   ```bash
   python scripts/analyze_rollout_timing.py --show-raw-output --min-output-tokens 500
   ```

2. å¦‚æœç¡®è®¤æœ‰ thinkingï¼Œè€ƒè™‘ï¼š
   - é™ä½ `MAX_TOKENS` é™åˆ¶è¾“å‡ºé•¿åº¦
   - ä¿®æ”¹ system prompt æ˜ç¡®è¦æ±‚"ç›´æ¥è¾“å‡ºå·¥å…·è°ƒç”¨ï¼Œä¸è¦æ€è€ƒ"
   - ä½¿ç”¨æ›´æ¿€è¿›çš„ `temperature` è®¾ç½®

#### 2. LLM ç”Ÿæˆé€Ÿåº¦æ…¢ï¼ˆ< 30 tokens/s on H200ï¼‰

**ç—‡çŠ¶**ï¼šH200 GPU ç”Ÿæˆé€Ÿåº¦åªæœ‰ 16 tokens/s

**å¯èƒ½åŸå› **ï¼š
1. `MAX_TOKENS` è®¾ç½®è¿‡é«˜ï¼ˆå¦‚ 4096ï¼‰
2. è¾“å…¥åºåˆ—è¿‡é•¿
3. æ¨¡å‹æœªæ­£ç¡®ä½¿ç”¨ GPU
4. æ‰¹å¤„ç†å¤§å°ä¸º 1

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. **é¦–è¦**ï¼šé™ä½ `MAX_TOKENS` åˆ° 512-1024
2. æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†é‡åŒ–ï¼ˆ`load_in_4bit=true`ï¼‰
3. ä½¿ç”¨ Flash Attentionï¼ˆUnsloth åº”è¯¥è‡ªåŠ¨å¯ç”¨ï¼‰
4. æŸ¥çœ‹ GPU åˆ©ç”¨ç‡ï¼š`nvidia-smi`

## æ—¥å¿—æ–‡ä»¶ç»“æ„

è¯¦ç»†æ—¥å¿—ä¿å­˜åœ¨ `outputs/rollout_logs/` ä¸‹ï¼š

```
outputs/rollout_logs/
â”œâ”€â”€ step_1/
â”‚   â”œâ”€â”€ query_q001/
â”‚   â”‚   â”œâ”€â”€ rollout_0.json
â”‚   â”‚   â”œâ”€â”€ rollout_1.json
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ query_q002/
â”‚       â””â”€â”€ ...
â””â”€â”€ step_2/
    â””â”€â”€ ...
```

æ¯ä¸ª JSON æ–‡ä»¶åŒ…å«ï¼š

```json
{
  "query_id": "q001",
  "step": 1,
  "rollout_index": 0,
  "query_total_time_ms": 45234.5,
  "turn_timings": [
    {
      "turn_number": 1,
      "llm_generation_time_ms": 1234.5,
      "llm_input_tokens": 1500,
      "llm_output_tokens": 150,
      "llm_raw_output": "...",  // åŸå§‹æ¨¡å‹è¾“å‡º
      "llm_raw_output_length": 850,
      "tool_execution_time_ms": 5.2,
      "turn_total_time_ms": 1240.0
    }
  ],
  "tool_calls": [...],
  "reward": 1.5,
  "rubric": {...}
}
```

## æ§åˆ¶ Thinking

### æ–¹æ³• 1ï¼šSystem Prompt ä¿®æ”¹

åœ¨ `link_search_agent/prompts.py` ä¸­çš„ system prompt æ·»åŠ ï¼š

```python
"""
IMPORTANT: Output tool calls directly without explanation or thinking.
Do not include reasoning or planning before tool calls.
"""
```

### æ–¹æ³• 2ï¼šä½¿ç”¨æ›´ä½çš„ temperature

é™ä½ temperature å¯ä»¥è®©æ¨¡å‹è¾“å‡ºæ›´ç¡®å®šã€æ›´ç®€æ´ï¼š

```python
policy_config = PolicyConfig(
    enable_dynamic_temperature=False,  # ç¦ç”¨åŠ¨æ€ temperature
    base_temperature=0.3,  # ä½¿ç”¨å›ºå®šçš„ä½ temperature
)
```

### æ–¹æ³• 3ï¼šPost-processing è¿‡æ»¤

å¦‚æœæ¨¡å‹åšæŒè¾“å‡º thinkingï¼Œå¯ä»¥åœ¨è§£ææ—¶è¿‡æ»¤æ‰ï¼š

```python
# åœ¨ agent.py çš„ _parse_tool_calls_from_response ä¸­
# åªæå– <tool_call> æ ‡ç­¾å†…çš„å†…å®¹ï¼Œå¿½ç•¥å…¶ä»–æ–‡æœ¬
```

## æ€§èƒ½åŸºå‡†

åœ¨ H200 + Qwen3-30B ä¸Šçš„é¢„æœŸæ€§èƒ½ï¼š

| é…ç½® | Tokens/s | è¯´æ˜ |
|------|----------|------|
| MAX_TOKENS=4096 | 15-20 | å¤ªæ…¢ï¼Œä¸æ¨è |
| MAX_TOKENS=1024 | 40-60 | åˆç† |
| MAX_TOKENS=512 | 60-100+ | æ¨èç”¨äºå·¥å…·è°ƒç”¨ |

## ç¤ºä¾‹è¾“å‡º

### è®­ç»ƒæ—¶çš„å®æ—¶æ—¥å¿—

```
â±ï¸  LLM Generation: 1234.56ms | Tokens: 1597 in / 150 out

ğŸ” Raw Model Output (850 chars, 150 tokens):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
<tool_call>{"name": "search_profile", "arguments": {"sql": "SELECT ..."}}</tool_call>
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â±ï¸  Tools Execution: 4.22ms
â±ï¸  Turn Total Time: 1240.00ms
```

### åˆ†æè„šæœ¬è¾“å‡º

```bash
$ python scripts/analyze_rollout_timing.py --min-output-tokens 500

ğŸ“Š Found 24 rollout logs
================================================================================

ğŸ“ˆ Performance Summary
================================================================================
Average tokens/second: 18.45
Average output tokens per turn: 523.2
Max output tokens in any turn: 772

ğŸ” Turns with >= 500 output tokens:
================================================================================

ğŸ“ Step 1, Query q001, Rollout 0, Turn 2
   Output tokens: 772
   LLM time: 47456.87ms
   Speed: 16.27 tokens/s
   Raw output length: 4523 chars
   âš ï¸  Likely contains thinking (ratio: 22.6x)
   
   Raw Output Preview:
   --------------------------------------------------------------------------
   Let me think about this query. The user wants to find investment 
   managers in Munich with PE experience. I should search for...
   --------------------------------------------------------------------------
```

## ä¸‹ä¸€æ­¥

1. ä½¿ç”¨ `--enable-detailed-logging` è¿è¡Œè®­ç»ƒ
2. ä½¿ç”¨åˆ†æè„šæœ¬æ£€æŸ¥æ˜¯å¦æœ‰ thinking
3. æ ¹æ®åˆ†æç»“æœè°ƒæ•´ `MAX_TOKENS`
4. å¦‚æœéœ€è¦ï¼Œä¿®æ”¹ system prompt æˆ–æ·»åŠ  thinking è¿‡æ»¤
