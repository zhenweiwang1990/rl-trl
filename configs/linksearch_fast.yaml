# Link Search Agent - Fast Training Configuration
# Optimized for H200 performance

# Model settings
model_name: "unsloth/Qwen3-32B"
max_seq_length: 16384  # 减少序列长度以提升速度
load_in_4bit: true

# LoRA settings
lora_r: 16
lora_alpha: 16
lora_dropout: 0.0
target_modules: ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]

# Training settings
num_train_epochs: 3
per_device_train_batch_size: 2
per_device_eval_batch_size: 4
gradient_accumulation_steps: 4
learning_rate: 1.0e-5
warmup_steps: 10
logging_steps: 1
save_steps: 10
eval_steps: 10
save_total_limit: 3

# GRPO settings
num_generations: 4
max_prompt_length: 4096
max_completion_length: 512  # 大幅降低，提升生成速度
temperature: 0.7
top_p: 0.9
beta: 0.01

# Link Search specific - 性能优化配置
max_turns: 15
max_profiles: 10
train_dataset_size: 1000
eval_dataset_size: 100
target_accuracy: 0.80

# Output
output_dir: "outputs/qwen3-32b-linksearch-fast"
wandb_project: "qwen3-32b-grpo-linksearch"
wandb_name: "fast-config"

# Misc
seed: 42
bf16: true
gradient_checkpointing: true
optim: "adamw_8bit"
max_grad_norm: 1.0
report_to: "wandb"
verbose: true
