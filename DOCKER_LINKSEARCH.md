# Link Search Agent Docker è®­ç»ƒæŒ‡å—

## ğŸ³ åœ¨ Docker ä¸­è®­ç»ƒ Link Search Agent

### å‰ç½®å‡†å¤‡

1. **æ„å»º Docker é•œåƒ**ï¼ˆå¦‚æœè¿˜æ²¡æ„å»ºï¼‰ï¼š
```bash
cd /home/zhlmmc/rl-trl
bash scripts/build.sh
```

2. **å‡†å¤‡æ•°æ®åº“æ–‡ä»¶**ï¼š
ç¡®ä¿ä½ æœ‰ SQLite æ•°æ®åº“æ–‡ä»¶ï¼ŒåŒ…å« LinkedIn ä¸ªäººèµ„æ–™æ•°æ®ã€‚

3. **è®¾ç½®ç¯å¢ƒå˜é‡**ï¼š
```bash
# HuggingFace Tokenï¼ˆå¿…éœ€ï¼‰
export HF_TOKEN="your_huggingface_token"

# æ•°æ®åº“è·¯å¾„ï¼ˆå¯é€‰ï¼Œå¦‚æœä¸è®¾ç½®ä¼šä½¿ç”¨å®¹å™¨å†…çš„é»˜è®¤è·¯å¾„ï¼‰
export PROFILE_DB_PATH="/home/zhlmmc/rl-people-search/link_search_agent/data/profiles.db"

# Wandb API Keyï¼ˆå¯é€‰ï¼‰
export WANDB_API_KEY="your_wandb_api_key"
```

### æ–¹å¼ 1: ä½¿ç”¨è‡ªåŠ¨è„šæœ¬ï¼ˆæ¨èï¼‰

#### å¯åŠ¨å®¹å™¨
```bash
# è®¾ç½®ç¯å¢ƒå˜é‡
export HF_TOKEN="your_token"
export PROFILE_DB_PATH="/path/to/profiles.db"

# è¿è¡Œå®¹å™¨ï¼ˆä¼šè‡ªåŠ¨æŒ‚è½½æ•°æ®åº“ï¼‰
bash scripts/run.sh
```

å®¹å™¨å¯åŠ¨åï¼Œä¼šæ˜¾ç¤ºå¯ç”¨å‘½ä»¤ï¼š
```
=== Qwen3-32B GRPO Training with TRL + Unsloth ===

Available training tasks:

1. Math Reasoning (GSM8K):
  - Run training: python train_grpo.py
  - With custom config: python train_grpo.py --config configs/custom.yaml

2. Link Search Agent:
  - Quick test: python train_grpo_linksearch.py --mode simple
  - Full training: python train_grpo_linksearch.py --mode masked
  - With detailed logs: python train_grpo_linksearch.py --mode masked --enable-detailed-logging
  - Or use script: ./scripts/train_linksearch.sh --mode masked

Other commands:
  - Test setup: python test_linksearch_setup.py
  - Run evaluation: python eval_model.py --checkpoint outputs/checkpoint-xxx
```

#### åœ¨å®¹å™¨å†…å¼€å§‹è®­ç»ƒ

**å¿«é€Ÿæµ‹è¯•**ï¼š
```bash
# æµ‹è¯•ç¯å¢ƒæ˜¯å¦æ­£ç¡®è®¾ç½®
python test_linksearch_setup.py

# å¿«é€Ÿæµ‹è¯•è®­ç»ƒï¼ˆsimple æ¨¡å¼ï¼‰
export TRAIN_DATASET_SIZE="50"
export EVAL_DATASET_SIZE="10"
export MAX_STEPS="20"
export WANDB_MODE="disabled"

python train_grpo_linksearch.py --mode simple
```

**å®Œæ•´è®­ç»ƒ**ï¼š
```bash
# ä½¿ç”¨ masked æ¨¡å¼ï¼ˆæ¨èï¼‰
export TRAIN_DATASET_SIZE="1000"
export EVAL_DATASET_SIZE="100"
export MAX_STEPS="200"
export TARGET_ACCURACY="0.80"

python train_grpo_linksearch.py --mode masked
```

**ä½¿ç”¨è®­ç»ƒè„šæœ¬**ï¼š
```bash
# ä½¿ç”¨ä¾¿æ·è„šæœ¬
./scripts/train_linksearch.sh --mode masked

# å¸¦è¯¦ç»†æ—¥å¿—
./scripts/train_linksearch.sh --mode masked --enable-detailed-logging

# æ¢å¤è®­ç»ƒ
./scripts/train_linksearch.sh --mode masked --resume

# ä»æœ€ä½³ checkpoint æ¢å¤
./scripts/train_linksearch.sh --mode masked --resume-best
```

### æ–¹å¼ 2: æ‰‹åŠ¨è¿è¡Œ Docker

å¦‚æœä½ æƒ³æ›´ç»†ç²’åº¦åœ°æ§åˆ¶ Docker è¿è¡Œï¼š

```bash
# æ‰‹åŠ¨è¿è¡Œå®¹å™¨
docker run -it --rm \
    --gpus all \
    --name qwen3-grpo-linksearch \
    --shm-size=32g \
    -v /home/zhlmmc/rl-trl:/workspace \
    -v $HOME/.cache/huggingface:/root/.cache/huggingface \
    -v /home/zhlmmc/rl-people-search/link_search_agent/data/profiles.db:/workspace/link_search_agent/data/profiles.db:ro \
    -e HF_TOKEN="$HF_TOKEN" \
    -e WANDB_API_KEY="$WANDB_API_KEY" \
    -e PROFILE_DB_PATH="/workspace/link_search_agent/data/profiles.db" \
    -p 6006:6006 \
    qwen3-grpo:latest
```

### æ•°æ®åº“æŒ‚è½½è¯´æ˜

æ•°æ®åº“æ–‡ä»¶ä¼šè¢«æŒ‚è½½åˆ°å®¹å™¨å†…çš„å›ºå®šè·¯å¾„ï¼š
- **å®¿ä¸»æœº**: `$PROFILE_DB_PATH`ï¼ˆä½ è®¾ç½®çš„è·¯å¾„ï¼‰
- **å®¹å™¨å†…**: `/workspace/link_search_agent/data/profiles.db`

å®¹å™¨å†…çš„ç¯å¢ƒå˜é‡ `PROFILE_DB_PATH` ä¼šè‡ªåŠ¨è®¾ç½®ä¸ºå®¹å™¨å†…è·¯å¾„ã€‚

### é…ç½®ç¯å¢ƒå˜é‡

åœ¨å®¹å™¨å†…ï¼Œä½ å¯ä»¥è®¾ç½®ä»¥ä¸‹ç¯å¢ƒå˜é‡æ¥é…ç½®è®­ç»ƒï¼š

```bash
# æ¨¡å‹é…ç½®
export MODEL_NAME="unsloth/Qwen3-32B"

# æ•°æ®é›†é…ç½®
export TRAIN_DATASET_SIZE="1000"
export EVAL_DATASET_SIZE="100"
export HF_DATASET_ID="gboxai/linksearch"

# è®­ç»ƒå‚æ•°
export MAX_STEPS="200"
export LEARNING_RATE="1e-5"
export PER_DEVICE_TRAIN_BATCH_SIZE="2"
export NUM_GENERATIONS="4"

# Agent é…ç½®
export MAX_TURNS="15"
export MAX_PROFILES="10"

# è®­ç»ƒç­–ç•¥
export TARGET_ACCURACY="0.80"
export OUTPUT_DIR="outputs/grpo_linksearch_masked"

# Wandb
export WANDB_PROJECT="link-search-grpo"
export WANDB_MODE="online"  # æˆ– "disabled"
```

### å®Œæ•´è®­ç»ƒç¤ºä¾‹

```bash
# 1. å¯åŠ¨å®¹å™¨ï¼ˆåœ¨å®¿ä¸»æœºä¸Šï¼‰
export HF_TOKEN="your_token"
export PROFILE_DB_PATH="/home/zhlmmc/rl-people-search/link_search_agent/data/profiles.db"
export WANDB_API_KEY="your_wandb_key"

bash scripts/run.sh

# 2. åœ¨å®¹å™¨å†…é…ç½®ç¯å¢ƒ
export TRAIN_DATASET_SIZE="1000"
export EVAL_DATASET_SIZE="100"
export MAX_STEPS="200"
export TARGET_ACCURACY="0.80"
export WANDB_PROJECT="link-search-grpo"
export WANDB_NAME="exp-masked-qwen32b"

# 3. å¼€å§‹è®­ç»ƒ
python train_grpo_linksearch.py --mode masked --enable-detailed-logging

# æˆ–ä½¿ç”¨è„šæœ¬
./scripts/train_linksearch.sh --mode masked --enable-detailed-logging
```

### ç›‘æ§è®­ç»ƒè¿›åº¦

**åœ¨å®¹å™¨å†…**ï¼š
```bash
# æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
tail -f logs/training.log

# æŸ¥çœ‹ GPU ä½¿ç”¨
nvidia-smi

# æŸ¥çœ‹è¾“å‡ºç›®å½•
ls -la outputs/grpo_linksearch_masked/
```

**åœ¨å®¿ä¸»æœºä¸Š**ï¼ˆå¦ä¸€ä¸ªç»ˆç«¯ï¼‰ï¼š
```bash
# è¿›å…¥è¿è¡Œä¸­çš„å®¹å™¨
docker exec -it qwen3-grpo-train bash

# æŸ¥çœ‹å®¹å™¨æ—¥å¿—
docker logs qwen3-grpo-train

# æŸ¥çœ‹ GPU ä½¿ç”¨
watch -n 1 nvidia-smi
```

**ä½¿ç”¨ Wandb**ï¼š
è®¿é—® https://wandb.ai/your-username/link-search-grpo

### ä¿å­˜å’Œæ¢å¤

è®­ç»ƒè¾“å‡ºä¼šè‡ªåŠ¨ä¿å­˜åˆ°å®¿ä¸»æœºçš„ `outputs/` ç›®å½•ï¼š
```bash
/home/zhlmmc/rl-trl/outputs/grpo_linksearch_masked/
â”œâ”€â”€ checkpoint-10/
â”œâ”€â”€ checkpoint-20/
â”œâ”€â”€ ...
â”œâ”€â”€ final/
â””â”€â”€ rollout_logs/  (å¦‚æœå¯ç”¨)
```

æ¢å¤è®­ç»ƒï¼š
```bash
# åœ¨å®¹å™¨å†…
python train_grpo_linksearch.py --mode masked --resume

# æˆ–ä»æœ€ä½³ checkpoint
python train_grpo_linksearch.py --mode masked --resume_best
```

### ä¸åŒè®­ç»ƒæ¨¡å¼å¯¹æ¯”

| æ¨¡å¼ | é€Ÿåº¦ | å‡†ç¡®åº¦ | é€‚ç”¨åœºæ™¯ |
|------|------|--------|----------|
| simple | æœ€å¿« | ä½ | å¿«é€Ÿæµ‹è¯•ç¯å¢ƒ |
| rollout | ä¸­ç­‰ | ä¸­ç­‰ | å®éªŒå’Œè°ƒè¯• |
| masked | æœ€æ…¢ | æœ€é«˜ | å®Œæ•´è®­ç»ƒï¼ˆæ¨èï¼‰ |

### èµ„æºéœ€æ±‚

**GPU æ˜¾å­˜**ï¼š
- Qwen3-32B + 4-bit + LoRA-16: ~20-24GB
- æ‰¹æ¬¡å¤§å° 2 + æ¢¯åº¦ç´¯ç§¯ 4: ~28-32GB
- å»ºè®®ï¼šRTX 4090 / A6000 / A100

**ç£ç›˜ç©ºé—´**ï¼š
- æ¨¡å‹ç¼“å­˜: ~30GB
- è®­ç»ƒè¾“å‡º: ~10-20GBï¼ˆå–å†³äº checkpoint æ•°é‡ï¼‰
- æ•°æ®åº“: ~1-10GBï¼ˆå–å†³äºæ•°æ®é‡ï¼‰

### æ•…éšœæ’æŸ¥

**é—®é¢˜ 1: æ‰¾ä¸åˆ°æ•°æ®åº“**
```bash
# æ£€æŸ¥æ•°æ®åº“æ˜¯å¦æ­£ç¡®æŒ‚è½½
ls -la /workspace/link_search_agent/data/profiles.db

# æ£€æŸ¥ç¯å¢ƒå˜é‡
echo $PROFILE_DB_PATH
```

**é—®é¢˜ 2: HuggingFace è®¤è¯å¤±è´¥**
```bash
# æ£€æŸ¥ token
echo $HF_TOKEN

# é‡æ–°è®¾ç½®
export HF_TOKEN="your_token"
huggingface-cli login
```

**é—®é¢˜ 3: æ˜¾å­˜ä¸è¶³**
```bash
# å‡å°æ‰¹æ¬¡å¤§å°
export PER_DEVICE_TRAIN_BATCH_SIZE="1"
export GRADIENT_ACCUMULATION_STEPS="8"

# æˆ–ä½¿ç”¨æ›´å°çš„æ¨¡å‹
export MODEL_NAME="unsloth/Qwen3-7B"
```

**é—®é¢˜ 4: å®¹å™¨æ— æ³•è®¿é—® GPU**
```bash
# æ£€æŸ¥ GPU æ˜¯å¦å¯ç”¨
nvidia-smi

# æ£€æŸ¥ Docker GPU æ”¯æŒ
docker run --rm --gpus all nvidia/cuda:11.8.0-base-ubuntu22.04 nvidia-smi
```

### æ€§èƒ½ä¼˜åŒ–

**åŠ é€Ÿè®­ç»ƒ**ï¼š
1. å¢åŠ  `gradient_accumulation_steps`ï¼ˆå¦‚æœæ˜¾å­˜å…è®¸ï¼‰
2. ä½¿ç”¨ `--enable-detailed-logging` ä»…åœ¨éœ€è¦æ—¶
3. å‡å° `MAX_TURNS`ï¼ˆå¦‚æœä»»åŠ¡å…è®¸ï¼‰
4. ä½¿ç”¨ SSD å­˜å‚¨æ•°æ®åº“å’Œè¾“å‡º

**èŠ‚çœæ˜¾å­˜**ï¼š
1. å‡å° `PER_DEVICE_TRAIN_BATCH_SIZE`
2. å‡å° `MAX_TOKENS`
3. å‡å° `NUM_GENERATIONS`
4. ä½¿ç”¨ 4-bit é‡åŒ–

### å¤š GPU è®­ç»ƒ

å¦‚æœæœ‰å¤šä¸ª GPUï¼š
```bash
# ä½¿ç”¨æ‰€æœ‰ GPU
docker run --gpus all ...

# ä½¿ç”¨ç‰¹å®š GPU
docker run --gpus '"device=0,1"' ...

# åœ¨å®¹å™¨å†…æ£€æŸ¥
nvidia-smi
```

### æ¸…ç†å’Œç»´æŠ¤

**æ¸…ç†å®¹å™¨**ï¼š
```bash
# åœæ­¢å®¹å™¨
docker stop qwen3-grpo-train

# åˆ é™¤å®¹å™¨
docker rm qwen3-grpo-train

# æ¸…ç†æ—§é•œåƒ
docker image prune
```

**æ¸…ç†è¾“å‡º**ï¼š
```bash
# åˆ é™¤æ—§ checkpointï¼ˆä¿ç•™æœ€ä½³å’Œæœ€æ–°ï¼‰
cd /home/zhlmmc/rl-trl/outputs/grpo_linksearch_masked
ls checkpoint-* | head -n -2 | xargs rm -rf
```

### ä¸‹ä¸€æ­¥

1. **æµ‹è¯•ç¯å¢ƒ**: `python test_linksearch_setup.py`
2. **å¿«é€Ÿæµ‹è¯•**: ä½¿ç”¨ simple æ¨¡å¼è®­ç»ƒ 20 æ­¥
3. **å®Œæ•´è®­ç»ƒ**: ä½¿ç”¨ masked æ¨¡å¼è®­ç»ƒåˆ°ç›®æ ‡ accuracy
4. **è¯„ä¼°æ¨¡å‹**: è¯„ä¼°è®­ç»ƒå¥½çš„æ¨¡å‹
5. **éƒ¨ç½²åº”ç”¨**: å°†æ¨¡å‹åº”ç”¨åˆ°å®é™…ä»»åŠ¡

### æœ‰ç”¨çš„å‘½ä»¤

```bash
# æŸ¥çœ‹å®¹å™¨èµ„æºä½¿ç”¨
docker stats qwen3-grpo-train

# æŸ¥çœ‹å®¹å™¨å†…è¿›ç¨‹
docker top qwen3-grpo-train

# å¤åˆ¶æ–‡ä»¶åˆ°å®¹å™¨
docker cp local_file.txt qwen3-grpo-train:/workspace/

# ä»å®¹å™¨å¤åˆ¶æ–‡ä»¶
docker cp qwen3-grpo-train:/workspace/outputs/model.pt ./

# æŸ¥çœ‹å®¹å™¨æ—¥å¿—
docker logs -f qwen3-grpo-train
```

## ğŸ“š ç›¸å…³æ–‡æ¡£

- **å¿«é€Ÿå…¥é—¨**: `QUICKSTART_LINKSEARCH.md`
- **è¯¦ç»†æ–‡æ¡£**: `LINKSEARCH_README.md`
- **è¿ç§»è¯´æ˜**: `MIGRATION_SUMMARY.md`
- **ä¸»æ–‡æ¡£**: `README.md`
