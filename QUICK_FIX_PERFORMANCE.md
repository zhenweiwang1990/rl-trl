# å¿«é€Ÿä¿®å¤ï¼šè§£å†³ LLM ç”Ÿæˆé€Ÿåº¦æ…¢çš„é—®é¢˜

## é—®é¢˜ç—‡çŠ¶

- H200 GPU ä¸Š Qwen3-30B ç”Ÿæˆé€Ÿåº¦åªæœ‰ **16 tokens/s**
- æ¯ä¸ª turn è€—æ—¶ **40+ ç§’**
- è¾“å‡º token æ•°å¼‚å¸¸é«˜ï¼ˆ**700+ tokens** ç”¨äºç®€å•å·¥å…·è°ƒç”¨ï¼‰

## æ ¹æœ¬åŸå› 

1. **`MAX_TOKENS=4096` è®¾ç½®è¿‡é«˜** - ä¸ºæ¯æ¬¡ç”Ÿæˆé¢„ç•™äº† 4096 tokens çš„ KV cache ç©ºé—´
2. **æ¨¡å‹å¯èƒ½è¾“å‡ºäº† thinking** - åœ¨å·¥å…·è°ƒç”¨å‰è¿›è¡Œæ¨ç†ï¼Œæµªè´¹ token

## å¿«é€Ÿè§£å†³æ–¹æ¡ˆ

### æ–¹æ¡ˆ 1ï¼šé™ä½ MAX_TOKENSï¼ˆç«‹å³è§æ•ˆï¼ï¼‰

ä¿®æ”¹ä½ çš„ç¯å¢ƒé…ç½®æ–‡ä»¶ï¼š

```bash
# åœ¨äº‘ä¸Šçš„ .env æˆ– env.linksearch æ–‡ä»¶ä¸­
MAX_TOKENS="512"  # ä» 4096 é™ä½åˆ° 512
```

**é¢„æœŸæ•ˆæœ**ï¼šé€Ÿåº¦æå‡ **3-5 å€**ï¼ˆä» 16 tokens/s æå‡åˆ° 50-80 tokens/sï¼‰

### æ–¹æ¡ˆ 2ï¼šå¯ç”¨è¯¦ç»†æ—¥å¿—æŸ¥çœ‹ Thinking

åœ¨è®­ç»ƒæ—¶æ·»åŠ å‚æ•°ï¼š

```bash
python train_grpo_linksearch.py --mode masked --enable-detailed-logging
```

ç„¶åä½¿ç”¨åˆ†æè„šæœ¬ï¼š

```bash
python scripts/analyze_rollout_timing.py --min-output-tokens 500 --show-raw-output
```

è¿™ä¼šå‘Šè¯‰ä½ æ¨¡å‹æ˜¯å¦åœ¨è¾“å‡º thinking å†…å®¹ã€‚

### æ–¹æ¡ˆ 3ï¼šå¦‚æœç¡®è®¤æœ‰ Thinkingï¼Œæ·»åŠ  System Prompt é™åˆ¶

ç¼–è¾‘ `link_search_agent/prompts.py`ï¼Œåœ¨ system prompt å¼€å¤´æ·»åŠ ï¼š

```python
"""
CRITICAL: Output tool calls directly in JSON format. 
DO NOT include any explanation, reasoning, or thinking before the tool call.
Respond ONLY with the tool call JSON.
"""
```

## ä½¿ç”¨æ–°é…ç½®

### å·²åˆ›å»ºçš„å¿«é€Ÿé…ç½®æ–‡ä»¶

ä½¿ç”¨ `configs/linksearch_fast.yaml`ï¼š

```bash
# è¿™ä¸ªé…ç½®å·²ç»ä¼˜åŒ–äº† max_completion_length ä¸º 512
python train_grpo_linksearch.py --mode masked --config configs/linksearch_fast.yaml
```

æˆ–è€…ç›´æ¥è®¾ç½®ç¯å¢ƒå˜é‡ï¼š

```bash
export MAX_TOKENS=512
python train_grpo_linksearch.py --mode masked
```

## Docker ä½¿ç”¨

å¦‚æœä½ åœ¨äº‘ä¸Šç”¨ Dockerï¼Œåœ¨å¯åŠ¨å®¹å™¨æ—¶ä¼ å…¥ç¯å¢ƒå˜é‡ï¼š

```bash
# æ–¹æ³• 1ï¼šåœ¨ Docker å¯åŠ¨è„šæœ¬ä¸­è®¾ç½®
export MAX_TOKENS=512
./scripts/docker_train_linksearch.sh

# æ–¹æ³• 2ï¼šä¿®æ”¹å®¹å™¨å†…çš„ .env æ–‡ä»¶
docker exec -it qwen3-grpo-linksearch bash
nano .env
# ä¿®æ”¹ MAX_TOKENS="512"
```

## éªŒè¯ä¿®å¤

è®­ç»ƒå¼€å§‹åï¼Œæ£€æŸ¥æ—¥å¿—ï¼š

### ä¿®å¤å‰ï¼š
```
â±ï¸  LLM Generation: 47456.87ms | Tokens: 1597 in / 772 out
```
- é€Ÿåº¦ï¼š16.27 tokens/s âŒ

### ä¿®å¤åï¼ˆé¢„æœŸï¼‰ï¼š
```
â±ï¸  LLM Generation: 2000.00ms | Tokens: 1597 in / 150 out
```
- é€Ÿåº¦ï¼š75 tokens/s âœ…

## æ€§èƒ½åŸºå‡†

| MAX_TOKENS | H200 é€Ÿåº¦ | é€‚ç”¨åœºæ™¯ |
|------------|-----------|---------|
| 4096 | 15-20 t/s | âŒ å¤ªæ…¢ |
| 2048 | 25-35 t/s | ğŸŸ¡ å‹‰å¼ºå¯ç”¨ |
| 1024 | 40-60 t/s | âœ… åˆç† |
| 512 | 60-100+ t/s | âœ…âœ… æ¨èï¼ˆå·¥å…·è°ƒç”¨ä»»åŠ¡ï¼‰|

## è¿˜éœ€è¦å¸®åŠ©ï¼Ÿ

æŸ¥çœ‹å®Œæ•´æ–‡æ¡£ï¼š`TIMING_ANALYSIS.md`

æˆ–è¿è¡Œè¯Šæ–­è„šæœ¬ï¼š

```bash
python scripts/analyze_rollout_timing.py --help
```
